{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK-4 (HW4)\n",
    "\n",
    "## Due 24 Feb 2016 (Friday, 11:59pm)\n",
    "\n",
    "**Important Note:** Before uploading your homework on Canvas, please name your file as following:\n",
    "\n",
    "*HW#_FirstLastName.ipynb*\n",
    "\n",
    "where \"#\" denotes the homework number, \"FirstLastName\" is the name of the student (for example, HW1_MickeyMouse.ipynb). Each student will hand in their own file even if two students in the cohort work together. If you work with another student, please write her/his name on top of the first cell (as a comment or Markdown cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question-1 (1.5/6 points):** Your grandma found your letter about the genetic algorithms very interesting (*though she didn't take your attempt of hacking her recipe that serious!!!*) and she wants to keep in touch with you to hear more about what you have learned at the FRI class this week (Week-5). Could you please give her a summary of what you've learned about the Artificial Neural Networks (ANN).\n",
    "\n",
    "**Notes:**\n",
    "* Please explain in **layman's terms** (**0.75/1.5 points**).\n",
    "* Try to **give a simple example** as similar to *recipe hacking* (**0.75/1.5 points**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your letter goes here:**\n",
    "\n",
    "Dear Grandma,\n",
    "Neural Networks are an interesting tool that allows for basic pattern recognition with computers. They work pretty simply! For instance, playing supermario. A neural network would be given the information of where the player is, whats around them, and at what speed the objects are approaching each other. Then it would undergo a series of decision making processes where certain patterns would be analyzed. At first, the neural network would do terribly, and run straight into objects. However, in cases where the neural network randomly hit jump right in front of an obstacle, it would survive longer. This would be detected and saved. An input obstacle would more heavily weight towards the decision to jump. The neural network would equate the pattern \"hit jump before an obstacle\" as being good. From then on, it would remember to hit jump in front of obstacles. This pattern continues until it eventually makes it way through the entire game.\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question-2 (4.5/6 points):** Solve **AND** and **OR** logic problems with a simple ANN without using hidden nodes like shown at the class. \n",
    "\n",
    "**NOTES:** \n",
    "* There are two inputs ($\\left[x_1,x_2\\right]$) and one output ($y$).\n",
    "* $ \\left[x_1,x_2\\right] \\in \\left\\{0,1\\right\\}$.\n",
    "* Use the relavent truth table as both the *training* and *test* data.\n",
    "* (**1 points**) Compute **z** (net input) and **a** (activation) values.\n",
    "* (**0.5 points**) **a** becomes your prediction value. You can simply use it to compute the error: $\\mathbf{E}=(y-\\hat{y})^2=(y-a)^2$.\n",
    "* (**3 points**) Minimize **E** by searching for appropriate hyperparameter values for the ANN (i.e., *weights*) using either of the following algorithms you implemented in **HW2** and **HW3**:\n",
    "**(a)** Hill Climbing (HC),\n",
    "**(b)** Genetic Algorithms (GA) using **DEAP**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t300   \n",
      "1  \t137   \n",
      "2  \t141   \n",
      "3  \t138   \n",
      "4  \t131   \n",
      "5  \t126   \n",
      "6  \t138   \n",
      "7  \t138   \n",
      "8  \t123   \n",
      "9  \t120   \n",
      "10 \t120   \n",
      "11 \t123   \n",
      "12 \t133   \n",
      "13 \t116   \n",
      "14 \t122   \n",
      "15 \t142   \n",
      "16 \t133   \n",
      "17 \t133   \n",
      "18 \t141   \n",
      "19 \t136   \n",
      "20 \t138   \n",
      "21 \t128   \n",
      "22 \t135   \n",
      "23 \t134   \n",
      "24 \t147   \n",
      "25 \t126   \n",
      "26 \t138   \n",
      "27 \t129   \n",
      "28 \t134   \n",
      "29 \t128   \n",
      "30 \t140   \n",
      "31 \t146   \n",
      "32 \t118   \n",
      "33 \t130   \n",
      "34 \t136   \n",
      "35 \t126   \n",
      "36 \t110   \n",
      "37 \t134   \n",
      "38 \t141   \n",
      "39 \t133   \n",
      "40 \t138   \n",
      "41 \t118   \n",
      "42 \t130   \n",
      "43 \t123   \n",
      "44 \t136   \n",
      "45 \t147   \n",
      "46 \t134   \n",
      "47 \t123   \n",
      "48 \t132   \n",
      "49 \t121   \n",
      "50 \t117   \n",
      "51 \t140   \n",
      "52 \t128   \n",
      "53 \t132   \n",
      "54 \t135   \n",
      "55 \t143   \n",
      "56 \t123   \n",
      "57 \t127   \n",
      "58 \t128   \n",
      "59 \t114   \n",
      "60 \t133   \n",
      "61 \t122   \n",
      "62 \t114   \n",
      "63 \t122   \n",
      "64 \t156   \n",
      "65 \t129   \n",
      "66 \t135   \n",
      "67 \t127   \n",
      "68 \t139   \n",
      "69 \t134   \n",
      "70 \t131   \n",
      "71 \t147   \n",
      "72 \t127   \n",
      "73 \t112   \n",
      "74 \t135   \n",
      "75 \t141   \n",
      "76 \t128   \n",
      "77 \t137   \n",
      "78 \t111   \n",
      "79 \t124   \n",
      "80 \t128   \n",
      "81 \t113   \n",
      "82 \t119   \n",
      "83 \t142   \n",
      "84 \t130   \n",
      "85 \t153   \n",
      "86 \t126   \n",
      "87 \t126   \n",
      "88 \t121   \n",
      "89 \t136   \n",
      "90 \t134   \n",
      "91 \t109   \n",
      "92 \t130   \n",
      "93 \t135   \n",
      "94 \t145   \n",
      "95 \t142   \n",
      "96 \t141   \n",
      "97 \t128   \n",
      "98 \t143   \n",
      "99 \t141   \n",
      "100\t148   \n",
      "101\t116   \n",
      "102\t134   \n",
      "103\t139   \n",
      "104\t124   \n",
      "105\t144   \n",
      "106\t146   \n",
      "107\t124   \n",
      "108\t127   \n",
      "109\t130   \n",
      "110\t125   \n",
      "111\t136   \n",
      "112\t143   \n",
      "113\t123   \n",
      "114\t132   \n",
      "115\t147   \n",
      "116\t159   \n",
      "117\t142   \n",
      "118\t106   \n",
      "119\t147   \n",
      "120\t124   \n",
      "121\t149   \n",
      "122\t130   \n",
      "123\t127   \n",
      "124\t110   \n",
      "125\t141   \n",
      "126\t119   \n",
      "127\t134   \n",
      "128\t145   \n",
      "129\t122   \n",
      "130\t147   \n",
      "131\t115   \n",
      "132\t129   \n",
      "133\t117   \n",
      "134\t132   \n",
      "135\t138   \n",
      "136\t139   \n",
      "137\t121   \n",
      "138\t120   \n",
      "139\t105   \n",
      "140\t146   \n",
      "141\t140   \n",
      "142\t107   \n",
      "143\t136   \n",
      "144\t139   \n",
      "145\t147   \n",
      "146\t137   \n",
      "147\t123   \n",
      "148\t128   \n",
      "149\t114   \n",
      "150\t153   \n",
      "151\t138   \n",
      "152\t147   \n",
      "153\t142   \n",
      "154\t121   \n",
      "155\t145   \n",
      "156\t113   \n",
      "157\t128   \n",
      "158\t135   \n",
      "159\t144   \n",
      "160\t146   \n",
      "161\t141   \n",
      "162\t117   \n",
      "163\t132   \n",
      "164\t116   \n",
      "165\t142   \n",
      "166\t130   \n",
      "167\t116   \n",
      "168\t145   \n",
      "169\t127   \n",
      "170\t128   \n",
      "171\t123   \n",
      "172\t141   \n",
      "173\t131   \n",
      "174\t135   \n",
      "175\t147   \n",
      "176\t132   \n",
      "177\t124   \n",
      "178\t121   \n",
      "179\t124   \n",
      "180\t133   \n",
      "181\t152   \n",
      "182\t142   \n",
      "183\t131   \n",
      "184\t138   \n",
      "185\t130   \n",
      "186\t121   \n",
      "187\t137   \n",
      "188\t132   \n",
      "189\t140   \n",
      "190\t135   \n",
      "191\t134   \n",
      "192\t133   \n",
      "193\t137   \n",
      "194\t122   \n",
      "195\t142   \n",
      "196\t137   \n",
      "197\t119   \n",
      "198\t129   \n",
      "199\t143   \n",
      "200\t137   \n",
      "the final set is\n",
      "[[[1.4901347977192805], [1.5044514917399272], [1.0934607194122639]]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'andFunction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3e6b570a9dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"the final set is\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mandSet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[1;32mprint\u001b[0m \u001b[0mandFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mandSet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'andFunction' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from deap import base, tools, creator, algorithms\n",
    "\n",
    "#andWeights = [[0],[0]];\n",
    "#orWeights = [[0],[0]];\n",
    "             \n",
    "def initWeights(min= 1, max = 2): # just inits the weights randomly, nothing special.\n",
    "    Weights = [0]\n",
    "    Weights[0]= random.randrange(min, max)\n",
    "    return Weights\n",
    "    \n",
    "\n",
    "def sigmoid(x): # sigmoid function\n",
    "    return 1/(1+np.e**(-x))\n",
    "\n",
    "def runFunction(weightSet):\n",
    "    yHatOne = np.dot([[0, 0, 1]], weightSet)\n",
    "    yHatTwo = np.dot([[1, 0, 1]], weightSet)\n",
    "    yHatThree = np.dot([[0, 1, 1]], weightSet)\n",
    "    yHatFour = np.dot([[1, 1, 1]], weightSet)\n",
    "    w = sigmoid(np.sum(yHatOne))\n",
    "    x = sigmoid(np.sum(yHatTwo))\n",
    "    y = sigmoid(np.sum(yHatThree))\n",
    "    z = sigmoid(np.sum(yHatFour))\n",
    "    return w,x,y,z;\n",
    "\n",
    "def fitnessEval(weightSet):\n",
    "    finalError = 0\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            targetVal = 0\n",
    "            if(i == 1 and j ==1):\n",
    "                targetVal = 1 \n",
    "            yHat = np.dot([[i, j, 1]], weightSet)\n",
    "            z = np.sum(yHat)\n",
    "            activationVal = sigmoid(z);\n",
    "            finalError += abs(targetVal - activationVal)\n",
    "    return (finalError,)\n",
    "\n",
    "def fitnessEval2(weightSet):\n",
    "    finalError = 0\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            targetVal = 0\n",
    "            if(i == 1 or j == 1):\n",
    "                targetVal = 1 \n",
    "            yHat = np.dot([[i, j, 1]], weightSet)\n",
    "            z = np.sum(yHat)\n",
    "            activationVal = sigmoid(z);\n",
    "            finalError += abs(targetVal - activationVal)\n",
    "    return (finalError,)\n",
    "\n",
    "def mutFloatShift(weightSet, indpb = 0.05, maxChange = 0.5):\n",
    "    for i in range(3):\n",
    "        if np.random.random() < indpb:\n",
    "            posChange = np.random.random()>0.5\n",
    "            posVal = -1\n",
    "            if(posChange):\n",
    "                posVal = 1\n",
    "            weightSet[i][0] = weightSet[i][0] + np.random.random() * maxChange * posVal;\n",
    "    return weightSet,\n",
    "\n",
    "    \n",
    "##\n",
    "##creator.create(\"FMax\", base.Fitness, weights = (1.0,))\n",
    "##creator.create(\"Individual\", list, fitness = creator.FMax)\n",
    "##\n",
    "##toolbox = base.Toolbox()\n",
    "##toolbox.register(\"bit\", random.randint, 0, 1)\n",
    "##toolbox.register(\"gen_individual\", tools.initRepeat, creator.Individual, toolbox.bit, 30)\n",
    "##toolbox.register(\"gen_population\", tools.initRepeat, list, toolbox.gen_individual)\n",
    "##\n",
    "    \n",
    "creator.create(\"fMax\", base.Fitness, weights = (-1.0,))\n",
    "creator.create(\"weightSet\", list, fitness = creator.fMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "\n",
    "toolbox.register(\"genWeightSet\", tools.initRepeat, creator.weightSet, initWeights, 3)\n",
    "toolbox.register(\"genAndWeightPopulation\", tools.initRepeat, list, toolbox.genWeightSet)\n",
    "toolbox.register(\"genOrWeightPopulation\", tools.initRepeat, list, toolbox.genWeightSet)\n",
    "toolbox.register(\"evaluate\", fitnessEval)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", mutFloatShift)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize = 3)\n",
    "\n",
    "finalPop = algorithms.eaSimple(toolbox.genAndWeightPopulation(n=300), toolbox, 0.2, 0.3, 200)\n",
    "andSet = tools.selBest(finalPop[0], 1)\n",
    "\n",
    "toolbox.register(\"evaluate\", fitnessEval2)\n",
    "finalOrPop = algorithms.eaSimple(toolbox.genAndWeightPopulation(n=300), toolbox, 0.2, 0.3, 200)\n",
    "orSet = tools.selBest(finalOrPop[0], 1)\n",
    "\n",
    "print \"\\nthe weights for the AND neural network is \"\n",
    "print andSet\n",
    "print runFunction(andSet)\n",
    "\n",
    "print \"\\nthe weights for the OR neural network is \"\n",
    "print orSet\n",
    "print runFunction(orSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question-3 (OPTIONAL):** Solve **XOR** logic problem using an ANN implementation of your choice:\n",
    "* You can use any built-in code as long as you give the reference to it.\n",
    "Example resources: \n",
    "    * [A Neural Network in 11 lines of Python (Part 1)](http://iamtrask.github.io/2015/07/12/basic-python-network/)\n",
    "    * [A Neural Network in 13 lines of Python (Part 2 - Gradient Descent)](https://iamtrask.github.io/2015/07/27/python-network-part2/)\n",
    "    * [Neural Networks Demystified](https://github.com/stephencwelch/Neural-Networks-Demystified)\n",
    "    * [Machine Learning Exercise 4 - Neural Networks](http://nbviewer.jupyter.org/github/jdwittenauer/ipython-notebooks/blob/master/ML-Exercise4.ipynb)\n",
    "* Keep in mind that **bias** node helps shifting the activation function (for instance, sigmoid function) left or right.    \n",
    "* Perform the same operations **without** using any hidden nodes. Are the results satisfactory?\n",
    "    * **NOTE:** You can again use your own **GA** or **HC** from the previous question if you don't want to deal with **backpropagation algorithm** (or gadient descent).\n",
    "* **If results are not satisfactory**, try implementing extra hidden node(s) to increase the complexity of the model (approximation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
